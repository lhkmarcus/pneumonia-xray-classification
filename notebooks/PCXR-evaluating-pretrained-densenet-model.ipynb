{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet-169 for Multi-class Classification of CXR Images\n",
    "\n",
    "### Objectives\n",
    "\n",
    "The aim of this notebook is to train variations of the DenseNet arhictecture on the Chest X-ray (Pneumonia) data set sourced from Kaggle. The images are composed of CXR scans representing normal lungs, bacterial pneumonia, and viral pneumonia.\n",
    "\n",
    "A variable classification head will be built on top of the chosen network, in which varying hyperparameters will be configured and evaluated. The experiment tracking will be conducted with the *Weights and Biases* platform. The optimal model will be selected based on a trade-off evaluation between **MCC score** and **validation loss**. \n",
    "\n",
    "### Machine Configurations\n",
    "\n",
    "`GPU` : NVIDIA GeForce RTX 4090;\n",
    "`CPU` : AMD Ryzen 7 3700X 8-Core Processor;\n",
    "`VRAM` : 24.0 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version :  2.10.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Memory growth set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Suppress TensorFlow messages:\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "print(\"TensorFlow version : \", tf.__version__)  # check TensorFlow version\n",
    "gpu = tf.config.list_physical_devices(\"GPU\")    # check if TensorFlow is using the GPU\n",
    "print(gpu)\n",
    "\n",
    "# Enable memory growth for GPU:\n",
    "try:\n",
    "   tf.config.experimental.set_memory_growth(gpu[0], True)\n",
    "   print(\"Memory growth set.\")\n",
    "except:\n",
    "    print(\"GPU runtime already initialised.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: \"WANDB_NOTEBOOK_NAME\"=\"PCXR-evaluating-pretrained-cnn-model\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarcus-lim\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure notebook name for WandB:\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"PCXR-evaluating-pretrained-cnn-model\"\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose method for hyperparameter selection:\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish objective to optimise:\n",
    "metric = {\n",
    "    \"name\": \"val_loss\",\n",
    "    \"goal\": \"minimize\"   \n",
    "    }\n",
    "\n",
    "sweep_config[\"metric\"] = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose hyperparameters to sweep:\n",
    "param_dict = {\n",
    "    \"batch_size\": {\n",
    "        \"values\": [16, 32, 64]\n",
    "        },\n",
    "    \"optimiser\": {\n",
    "        \"values\": [\"adam\", \"sgd\"]\n",
    "        },\n",
    "    \"fc_layer_size\": {\n",
    "        \"values\": [32, 64, 128, 256]\n",
    "        },\n",
    "    \"dropout_1\": {\n",
    "        \"values\": [0.2, 0.6, 0.8]\n",
    "        },\n",
    "    \"dropout_2\": {\n",
    "        \"values\": [0.2, 0.6, 0.8]\n",
    "        },\n",
    "    \"dropout_3\": {\n",
    "        \"values\": [0.2, 0.6, 0.8]\n",
    "        },\n",
    "    }\n",
    "\n",
    "sweep_config[\"parameters\"] = param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate constant value for epoch:\n",
    "param_dict.update({\n",
    "    \"epochs\": {\n",
    "        \"value\": 10}\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use uniform distribution for learning rate:\n",
    "param_dict.update({\n",
    "    \"learning_rate\": {\n",
    "        \"distribution\": \"uniform\",\n",
    "        \"min\": 0.0001,\n",
    "        \"max\": 0.005\n",
    "      }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'bayes',\n",
      " 'metric': {'goal': 'minimize', 'name': 'val_loss'},\n",
      " 'parameters': {'batch_size': {'values': [16, 32, 64]},\n",
      "                'dropout_1': {'values': [0.2, 0.6, 0.8]},\n",
      "                'dropout_2': {'values': [0.2, 0.6, 0.8]},\n",
      "                'dropout_3': {'values': [0.2, 0.6, 0.8]},\n",
      "                'epochs': {'value': 10},\n",
      "                'fc_layer_size': {'values': [32, 64, 128, 256]},\n",
      "                'learning_rate': {'distribution': 'uniform',\n",
      "                                  'max': 0.005,\n",
      "                                  'min': 0.0001},\n",
      "                'optimiser': {'values': ['adam', 'sgd']}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datasets(train_dir=\"..\\\\artifacts\\\\train\",\n",
    "                   test_dir=\"..\\\\artifacts\\\\test\",\n",
    "                   class_names=[\"normal\", \"bacteria\", \"virus\"],\n",
    "                   batch_size=32,\n",
    "                   image_size=(300, 300),\n",
    "                   val_split=0.2):\n",
    "    \n",
    "    train_ds, valid_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory=train_dir,\n",
    "        label_mode=\"int\",\n",
    "        class_names=class_names,\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        validation_split=val_split,\n",
    "        subset=\"both\")\n",
    "\n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory=test_dir,\n",
    "        label_mode=\"int\",\n",
    "        class_names=class_names,\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        subset=None)\n",
    "    \n",
    "    return (train_ds, valid_ds, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(fc_layer_size=128, dropout_1=0.2, dropout_2=0.2, dropout_3=0.2):\n",
    "\n",
    "    # Configure image shape for model input shape\n",
    "    IMG_SHAPE = (300, 300, 3)\n",
    "\n",
    "    # Instantiate base model\n",
    "    base_model = tf.keras.applications.densenet.DenseNet169(\n",
    "        input_shape=IMG_SHAPE,\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\")\n",
    "\n",
    "    # Freeze convolutional base\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
    "\n",
    "    # Add an augmentation layer for additional training data\n",
    "    augment_layer = tf.keras.Sequential([\n",
    "        tf.keras.layers.RandomContrast(factor=0.2, seed=42),\n",
    "        tf.keras.layers.RandomBrightness(factor=0.2, seed=42),\n",
    "        tf.keras.layers.RandomRotation(factor=0.01, seed=42)\n",
    "    ])\n",
    "\n",
    "    # Establish base model architecture:\n",
    "    x = augment_layer(inputs)\n",
    "    x = tf.keras.applications.densenet.preprocess_input(x)\n",
    "    x = base_model(x, training=False)    # Prevent training of BN layers\n",
    "\n",
    "    # Add custom classification head:\n",
    "    x = tf.keras.layers.MaxPooling2D(input_shape=(1664,))(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_1)(x)  # Prevent overfitting\n",
    "    x = tf.keras.layers.Dense(fc_layer_size, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_2)(x)\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_3)(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(3, activation=\"softmax\")(x)\n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define optimiser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimiser(learning_rate=0.0001, optimiser=\"adam\"):\n",
    "    if optimiser.lower() == \"adam\":\n",
    "        return tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    if optimiser.lower() == \"sgd\":\n",
    "        return tf.keras.optimizers.SGD(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create callback to log custom metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MCC, F1, and AUC scores and log in WandB:\n",
    "class CustomLogCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model, x_val, y_val):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "\n",
    "        # Instantiate standalone metrics:\n",
    "        self._mcc = tf.keras.metrics.Mean(name=\"mcc\")\n",
    "        self._f1score = tf.keras.metrics.Mean(name=\"f1_score\")\n",
    "        self._aucroc = tf.keras.metrics.AUC(name=\"auc_roc\")\n",
    "\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epoch += 1\n",
    "\n",
    "        self._mcc.reset_state()\n",
    "        self._f1score.reset_state()\n",
    "        self._aucroc.reset_state()\n",
    "\n",
    "        print(\"Generating predictions and computing metrics for Epoch {} \".format(self.epoch))\n",
    "        predictions = self.model.predict(self.x_val)\n",
    "\n",
    "        f1score = f1_score(self.y_val, np.argmax(predictions, axis=-1),\n",
    "                           average=None)\n",
    "        mcc = matthews_corrcoef(self.y_val, np.argmax(predictions, axis=-1))\n",
    "\n",
    "        self._mcc.update_state(mcc)\n",
    "        self._f1score.update_state(f1score)\n",
    "        self._aucroc.update_state(self.y_val, np.argmax(predictions, axis=-1))\n",
    "\n",
    "        print(\"training loss : {} , training acc : {} , mcc score : {}\".format(\n",
    "            logs[\"loss\"], logs[\"accuracy\"], self._mcc.result().numpy()\n",
    "        ))\n",
    "        print(\"aucroc score  : {} , f1 score     : {} \".format(\n",
    "            self._aucroc.result().numpy(), self._f1score.result().numpy()\n",
    "        ))\n",
    "\n",
    "        # Log metrics to WandB:\n",
    "        wandb.log({\"mcc\": self._mcc.result().numpy(),\n",
    "                   \"fmeasure\": self._f1score.result().numpy(),\n",
    "                   \"auc_roc\": self._aucroc.result().numpy()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4684 files belonging to 3 classes.\n",
      "Using 3748 files for training.\n",
      "Using 936 files for validation.\n",
      "Found 1172 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Build data sets outside of train function:\n",
    "train_ds, valid_ds, _ = build_datasets(batch_size=None)\n",
    "\n",
    "# Convert validation data to arrays for custom metric computation:\n",
    "x_val = np.reshape(np.concatenate([x for x, _ in valid_ds], axis=0), (936, 300, 300, 3))\n",
    "y_val = np.concatenate(np.reshape([y for _, y in valid_ds], (1, 936)), axis=0)\n",
    "\n",
    "def train(model, batch_size=32, epochs=10, learning_rate=0.0001, optimiser_name=\"adam\"):\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    train_ds, valid_ds, _ = build_datasets(batch_size=batch_size)\n",
    "    optimiser = build_optimiser(learning_rate=learning_rate, optimiser=optimiser_name)\n",
    "\n",
    "    # Compile model:\n",
    "    model.compile(optimizer=optimiser,\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    # Fit model:\n",
    "    # Configure callbacks:\n",
    "    callbacks = [CustomLogCallback(model, x_val, y_val),\n",
    "                 wandb.keras.WandbMetricsLogger()]\n",
    "                 \n",
    "    # Train model:\n",
    "    model.fit(train_ds, \n",
    "              epochs=epochs,\n",
    "              validation_data=valid_ds, \n",
    "              callbacks=callbacks, \n",
    "              verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop training function in sweep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_train(config_defaults=None):\n",
    "    \n",
    "    # Initialise wandb and start run:\n",
    "    with wandb.init(config=config_defaults):\n",
    "        \n",
    "        wandb.config.architecture = \"DenseNet\"\n",
    "        wandb.config.dataset = \"Chest X-Ray Images (Pneumonia)\"\n",
    "        wandb.config.num_classes = 3\n",
    "        wandb.notes = \"Sweeping through DenseNet model variations\"\n",
    "\n",
    "        model = build_network(wandb.config.fc_layer_size,\n",
    "                              wandb.config.dropout_1,\n",
    "                              wandb.config.dropout_2,\n",
    "                              wandb.config.dropout_3)\n",
    "\n",
    "        train(model=model, \n",
    "              batch_size=wandb.config.batch_size,\n",
    "              epochs=wandb.config.epochs, \n",
    "              learning_rate=wandb.config.learning_rate,\n",
    "              optimiser_name=wandb.config.optimiser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise sweep and run agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: kjecbfle\n",
      "Sweep URL: https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"PCXR-evaluating-densenet-model-variations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t4jk2lm2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_1: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_2: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_3: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005869039959197109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Projects\\pneumonia-xray-classification\\notebooks\\wandb\\run-20230808_231402-t4jk2lm2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/t4jk2lm2' target=\"_blank\">ethereal-sweep-1</a></strong> to <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/t4jk2lm2' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/t4jk2lm2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4684 files belonging to 3 classes.\n",
      "Using 3748 files for training.\n",
      "Using 936 files for validation.\n",
      "Found 1172 files belonging to 3 classes.\n",
      "Generating predictions and computing metrics for Epoch 1 \n",
      "30/30 [==============================] - 4s 70ms/step\n",
      "training loss : 1.8146089315414429 , training acc : 0.35058698058128357 , mcc score : 0.029230903834104538\n",
      "aucroc score  : 0.5062130093574524 , f1 score     : 0.15713275969028473 \n",
      "Generating predictions and computing metrics for Epoch 2 \n",
      "30/30 [==============================] - 2s 67ms/step\n",
      "training loss : 1.6669343709945679 , training acc : 0.3788687288761139 , mcc score : 0.20938295125961304\n",
      "aucroc score  : 0.6241124272346497 , f1 score     : 0.34172549843788147 \n",
      "Generating predictions and computing metrics for Epoch 3 \n",
      "30/30 [==============================] - 2s 68ms/step\n",
      "training loss : 1.6729501485824585 , training acc : 0.380736380815506 , mcc score : 0.4124642014503479\n",
      "aucroc score  : 0.7800295948982239 , f1 score     : 0.548675000667572 \n",
      "Generating predictions and computing metrics for Epoch 4 \n",
      "30/30 [==============================] - 2s 67ms/step\n",
      "training loss : 1.5180202722549438 , training acc : 0.43036285042762756 , mcc score : 0.5358524918556213\n",
      "aucroc score  : 0.8664201498031616 , f1 score     : 0.6600179076194763 \n",
      "Generating predictions and computing metrics for Epoch 5 \n",
      "30/30 [==============================] - 2s 67ms/step\n",
      "training loss : 1.4302281141281128 , training acc : 0.4442369341850281 , mcc score : 0.5669930577278137\n",
      "aucroc score  : 0.8844674229621887 , f1 score     : 0.6830363869667053 \n",
      "Generating predictions and computing metrics for Epoch 6 \n",
      "30/30 [==============================] - 2s 67ms/step\n",
      "training loss : 1.3847386837005615 , training acc : 0.4730522930622101 , mcc score : 0.601000189781189\n",
      "aucroc score  : 0.8965976238250732 , f1 score     : 0.7113921046257019 \n",
      "Generating predictions and computing metrics for Epoch 7 \n",
      "30/30 [==============================] - 2s 67ms/step\n",
      "training loss : 1.317772388458252 , training acc : 0.4797225296497345 , mcc score : 0.6158486008644104\n",
      "aucroc score  : 0.9025147557258606 , f1 score     : 0.7245936989784241 \n",
      "Generating predictions and computing metrics for Epoch 8 \n",
      "30/30 [==============================] - 2s 67ms/step\n",
      "training loss : 1.3015940189361572 , training acc : 0.4933297634124756 , mcc score : 0.6174312829971313\n",
      "aucroc score  : 0.9044378995895386 , f1 score     : 0.721714437007904 \n",
      "Generating predictions and computing metrics for Epoch 9 \n",
      "30/30 [==============================] - 2s 67ms/step\n",
      "training loss : 1.247320532798767 , training acc : 0.5080042481422424 , mcc score : 0.6286436915397644\n",
      "aucroc score  : 0.9096153974533081 , f1 score     : 0.7371730804443359 \n",
      "Generating predictions and computing metrics for Epoch 10 \n",
      "30/30 [==============================] - 2s 67ms/step\n",
      "training loss : 1.2275080680847168 , training acc : 0.5258804559707642 , mcc score : 0.6385929584503174\n",
      "aucroc score  : 0.9174556136131287 , f1 score     : 0.7451090216636658 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>▁▃▆▇▇█████</td></tr><tr><td>epoch/accuracy</td><td>▁▂▂▄▅▆▆▇▇█</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▆▄▃▃▂▂▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▃▅▇▇█████</td></tr><tr><td>epoch/val_loss</td><td>█▅▃▃▂▂▁▁▁▁</td></tr><tr><td>fmeasure</td><td>▁▃▆▇▇█████</td></tr><tr><td>mcc</td><td>▁▃▅▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>0.91746</td></tr><tr><td>epoch/accuracy</td><td>0.52588</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.00059</td></tr><tr><td>epoch/loss</td><td>1.22751</td></tr><tr><td>epoch/val_accuracy</td><td>0.76709</td></tr><tr><td>epoch/val_loss</td><td>0.677</td></tr><tr><td>fmeasure</td><td>0.74511</td></tr><tr><td>mcc</td><td>0.63859</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-sweep-1</strong> at: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/t4jk2lm2' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/t4jk2lm2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230808_231402-t4jk2lm2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: brngfvbo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_1: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_2: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_3: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.003475100319230413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Projects\\pneumonia-xray-classification\\notebooks\\wandb\\run-20230808_233114-brngfvbo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/brngfvbo' target=\"_blank\">daily-sweep-2</a></strong> to <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/brngfvbo' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/brngfvbo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4684 files belonging to 3 classes.\n",
      "Using 3748 files for training.\n",
      "Using 936 files for validation.\n",
      "Found 1172 files belonging to 3 classes.\n",
      "Generating predictions and computing metrics for Epoch 1 \n",
      "30/30 [==============================] - 4s 68ms/step\n",
      "training loss : 0.5920528769493103 , training acc : 0.7585378885269165 , mcc score : 0.6627742648124695\n",
      "aucroc score  : 0.9221893548965454 , f1 score     : 0.7414975166320801 \n",
      "Generating predictions and computing metrics for Epoch 2 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 0.5068715810775757 , training acc : 0.7929562330245972 , mcc score : 0.6490806341171265\n",
      "aucroc score  : 0.9220414161682129 , f1 score     : 0.7474175095558167 \n",
      "Generating predictions and computing metrics for Epoch 3 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 0.491942435503006 , training acc : 0.7982923984527588 , mcc score : 0.6932045221328735\n",
      "aucroc score  : 0.9334319829940796 , f1 score     : 0.7858052253723145 \n",
      "Generating predictions and computing metrics for Epoch 4 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 0.4827336072921753 , training acc : 0.8004269003868103 , mcc score : 0.7141013145446777\n",
      "aucroc score  : 0.9399408102035522 , f1 score     : 0.8039364218711853 \n",
      "Generating predictions and computing metrics for Epoch 5 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 0.46782058477401733 , training acc : 0.8041622042655945 , mcc score : 0.6836867928504944\n",
      "aucroc score  : 0.9362425804138184 , f1 score     : 0.7670029997825623 \n",
      "Generating predictions and computing metrics for Epoch 6 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 0.4647800326347351 , training acc : 0.8143009543418884 , mcc score : 0.6973926424980164\n",
      "aucroc score  : 0.9335798621177673 , f1 score     : 0.7926362156867981 \n",
      "Generating predictions and computing metrics for Epoch 7 \n",
      "30/30 [==============================] - 2s 67ms/step\n",
      "training loss : 0.45558348298072815 , training acc : 0.8097652196884155 , mcc score : 0.6810682415962219\n",
      "aucroc score  : 0.9389052987098694 , f1 score     : 0.7705378532409668 \n",
      "Generating predictions and computing metrics for Epoch 8 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 0.45511263608932495 , training acc : 0.812700092792511 , mcc score : 0.6849219799041748\n",
      "aucroc score  : 0.9381656646728516 , f1 score     : 0.7723260521888733 \n",
      "Generating predictions and computing metrics for Epoch 9 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 0.4456864893436432 , training acc : 0.8180362582206726 , mcc score : 0.6875470280647278\n",
      "aucroc score  : 0.9437869787216187 , f1 score     : 0.7722053527832031 \n",
      "Generating predictions and computing metrics for Epoch 10 \n",
      "30/30 [==============================] - 2s 67ms/step\n",
      "training loss : 0.443803608417511 , training acc : 0.8164354562759399 , mcc score : 0.6800432801246643\n",
      "aucroc score  : 0.9390532374382019 , f1 score     : 0.7580162882804871 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>▁▁▅▇▆▅▆▆█▆</td></tr><tr><td>epoch/accuracy</td><td>▁▅▆▆▆█▇▇██</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▃▃▂▂▂▂▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▃▁▆█▅▆▅▅▅▅</td></tr><tr><td>epoch/val_loss</td><td>▆█▂▂▁▁▃▁▂▂</td></tr><tr><td>fmeasure</td><td>▁▂▆█▄▇▄▄▄▃</td></tr><tr><td>mcc</td><td>▂▁▆█▅▆▄▅▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>0.93905</td></tr><tr><td>epoch/accuracy</td><td>0.81644</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.00348</td></tr><tr><td>epoch/loss</td><td>0.4438</td></tr><tr><td>epoch/val_accuracy</td><td>0.79808</td></tr><tr><td>epoch/val_loss</td><td>0.4815</td></tr><tr><td>fmeasure</td><td>0.75802</td></tr><tr><td>mcc</td><td>0.68004</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">daily-sweep-2</strong> at: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/brngfvbo' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/brngfvbo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230808_233114-brngfvbo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bo2pucn9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_1: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_2: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_3: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00029736758267100204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Projects\\pneumonia-xray-classification\\notebooks\\wandb\\run-20230808_234311-bo2pucn9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/bo2pucn9' target=\"_blank\">sandy-sweep-3</a></strong> to <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/bo2pucn9' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/bo2pucn9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4684 files belonging to 3 classes.\n",
      "Using 3748 files for training.\n",
      "Using 936 files for validation.\n",
      "Found 1172 files belonging to 3 classes.\n",
      "Generating predictions and computing metrics for Epoch 1 \n",
      "30/30 [==============================] - 4s 68ms/step\n",
      "training loss : 1.2269694805145264 , training acc : 0.35779082775115967 , mcc score : 0.1115047037601471\n",
      "aucroc score  : 0.6230769157409668 , f1 score     : 0.4031611979007721 \n",
      "Generating predictions and computing metrics for Epoch 2 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 1.1654435396194458 , training acc : 0.3991461992263794 , mcc score : 0.2979612350463867\n",
      "aucroc score  : 0.7034023404121399 , f1 score     : 0.412041038274765 \n",
      "Generating predictions and computing metrics for Epoch 3 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 1.1246991157531738 , training acc : 0.4226253926753998 , mcc score : 0.3714340925216675\n",
      "aucroc score  : 0.7452662587165833 , f1 score     : 0.44008636474609375 \n",
      "Generating predictions and computing metrics for Epoch 4 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 1.055877447128296 , training acc : 0.4653148353099823 , mcc score : 0.40509724617004395\n",
      "aucroc score  : 0.7710059285163879 , f1 score     : 0.45635196566581726 \n",
      "Generating predictions and computing metrics for Epoch 5 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 1.0225441455841064 , training acc : 0.505069375038147 , mcc score : 0.4333745837211609\n",
      "aucroc score  : 0.7942308187484741 , f1 score     : 0.4783886969089508 \n",
      "Generating predictions and computing metrics for Epoch 6 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 1.002654790878296 , training acc : 0.5122731924057007 , mcc score : 0.45455095171928406\n",
      "aucroc score  : 0.80843186378479 , f1 score     : 0.491896390914917 \n",
      "Generating predictions and computing metrics for Epoch 7 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.9733660817146301 , training acc : 0.5349519848823547 , mcc score : 0.46476536989212036\n",
      "aucroc score  : 0.8162721395492554 , f1 score     : 0.4974285066127777 \n",
      "Generating predictions and computing metrics for Epoch 8 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.9461986422538757 , training acc : 0.5578975677490234 , mcc score : 0.4785325825214386\n",
      "aucroc score  : 0.8211538195610046 , f1 score     : 0.5126447081565857 \n",
      "Generating predictions and computing metrics for Epoch 9 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.9211746454238892 , training acc : 0.5667022466659546 , mcc score : 0.49611586332321167\n",
      "aucroc score  : 0.8337278366088867 , f1 score     : 0.5272125601768494 \n",
      "Generating predictions and computing metrics for Epoch 10 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.9140675663948059 , training acc : 0.5779082179069519 , mcc score : 0.5023501515388489\n",
      "aucroc score  : 0.8396449685096741 , f1 score     : 0.5358113646507263 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>▁▄▅▆▇▇▇▇██</td></tr><tr><td>epoch/accuracy</td><td>▁▂▃▄▆▆▇▇██</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▆▄▃▃▂▂▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▄▅▆▇▇▇▇██</td></tr><tr><td>epoch/val_loss</td><td>█▇▅▅▄▃▂▂▁▁</td></tr><tr><td>fmeasure</td><td>▁▁▃▄▅▆▆▇██</td></tr><tr><td>mcc</td><td>▁▄▆▆▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>0.83964</td></tr><tr><td>epoch/accuracy</td><td>0.57791</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.0003</td></tr><tr><td>epoch/loss</td><td>0.91407</td></tr><tr><td>epoch/val_accuracy</td><td>0.66774</td></tr><tr><td>epoch/val_loss</td><td>0.80961</td></tr><tr><td>fmeasure</td><td>0.53581</td></tr><tr><td>mcc</td><td>0.50235</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sandy-sweep-3</strong> at: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/bo2pucn9' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/bo2pucn9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230808_234311-bo2pucn9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: udkxzwl3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_1: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_2: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_3: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.003602042265370645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Projects\\pneumonia-xray-classification\\notebooks\\wandb\\run-20230808_235501-udkxzwl3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/udkxzwl3' target=\"_blank\">elated-sweep-4</a></strong> to <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/udkxzwl3' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/udkxzwl3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4684 files belonging to 3 classes.\n",
      "Using 3748 files for training.\n",
      "Using 936 files for validation.\n",
      "Found 1172 files belonging to 3 classes.\n",
      "Generating predictions and computing metrics for Epoch 1 \n",
      "30/30 [==============================] - 4s 68ms/step\n",
      "training loss : 1.2899694442749023 , training acc : 0.40741729736328125 , mcc score : 0.42155399918556213\n",
      "aucroc score  : 0.764349102973938 , f1 score     : 0.5117565393447876 \n",
      "Generating predictions and computing metrics for Epoch 2 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 1.084687352180481 , training acc : 0.5093383193016052 , mcc score : 0.5340147614479065\n",
      "aucroc score  : 0.8500000238418579 , f1 score     : 0.6229173541069031 \n",
      "Generating predictions and computing metrics for Epoch 3 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.9957923889160156 , training acc : 0.5514941215515137 , mcc score : 0.6067304015159607\n",
      "aucroc score  : 0.9048816561698914 , f1 score     : 0.7087897658348083 \n",
      "Generating predictions and computing metrics for Epoch 4 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.9291055202484131 , training acc : 0.5867128968238831 , mcc score : 0.6154307723045349\n",
      "aucroc score  : 0.9091716408729553 , f1 score     : 0.7029491066932678 \n",
      "Generating predictions and computing metrics for Epoch 5 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.893611490726471 , training acc : 0.602454662322998 , mcc score : 0.6227731704711914\n",
      "aucroc score  : 0.9162722229957581 , f1 score     : 0.7250707745552063 \n",
      "Generating predictions and computing metrics for Epoch 6 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.8779935240745544 , training acc : 0.61392742395401 , mcc score : 0.6230044960975647\n",
      "aucroc score  : 0.9143490791320801 , f1 score     : 0.7326524257659912 \n",
      "Generating predictions and computing metrics for Epoch 7 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.8227413296699524 , training acc : 0.6456776857376099 , mcc score : 0.6391688585281372\n",
      "aucroc score  : 0.9167159795761108 , f1 score     : 0.7408506870269775 \n",
      "Generating predictions and computing metrics for Epoch 8 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.798241376876831 , training acc : 0.6576840877532959 , mcc score : 0.6387012004852295\n",
      "aucroc score  : 0.914053201675415 , f1 score     : 0.7339179515838623 \n",
      "Generating predictions and computing metrics for Epoch 9 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.7795016765594482 , training acc : 0.6632871031761169 , mcc score : 0.6336157917976379\n",
      "aucroc score  : 0.915976345539093 , f1 score     : 0.7292837500572205 \n",
      "Generating predictions and computing metrics for Epoch 10 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.7745394706726074 , training acc : 0.6632871031761169 , mcc score : 0.6416716575622559\n",
      "aucroc score  : 0.923372745513916 , f1 score     : 0.7329315543174744 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>▁▅▇▇██████</td></tr><tr><td>epoch/accuracy</td><td>▁▄▅▆▆▇████</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▅▄▃▃▂▂▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▅▇▇▇█████</td></tr><tr><td>epoch/val_loss</td><td>█▅▃▃▂▂▂▁▁▁</td></tr><tr><td>fmeasure</td><td>▁▄▇▇██████</td></tr><tr><td>mcc</td><td>▁▅▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>0.92337</td></tr><tr><td>epoch/accuracy</td><td>0.66329</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.0036</td></tr><tr><td>epoch/loss</td><td>0.77454</td></tr><tr><td>epoch/val_accuracy</td><td>0.77244</td></tr><tr><td>epoch/val_loss</td><td>0.59182</td></tr><tr><td>fmeasure</td><td>0.73293</td></tr><tr><td>mcc</td><td>0.64167</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">elated-sweep-4</strong> at: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/udkxzwl3' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/udkxzwl3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230808_235501-udkxzwl3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wgrkt0cq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_1: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_2: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_3: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0032782040756396545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Projects\\pneumonia-xray-classification\\notebooks\\wandb\\run-20230809_001136-wgrkt0cq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/wgrkt0cq' target=\"_blank\">cerulean-sweep-5</a></strong> to <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/wgrkt0cq' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/wgrkt0cq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4684 files belonging to 3 classes.\n",
      "Using 3748 files for training.\n",
      "Using 936 files for validation.\n",
      "Found 1172 files belonging to 3 classes.\n",
      "Generating predictions and computing metrics for Epoch 1 \n",
      "30/30 [==============================] - 4s 69ms/step\n",
      "training loss : 0.7699248790740967 , training acc : 0.6846318244934082 , mcc score : 0.6441649198532104\n",
      "aucroc score  : 0.9326923489570618 , f1 score     : 0.7173476815223694 \n",
      "Generating predictions and computing metrics for Epoch 2 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.6254116296768188 , training acc : 0.7459978461265564 , mcc score : 0.6141403913497925\n",
      "aucroc score  : 0.9195266366004944 , f1 score     : 0.6793274879455566 \n",
      "Generating predictions and computing metrics for Epoch 3 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.5705393552780151 , training acc : 0.7697438597679138 , mcc score : 0.6738559603691101\n",
      "aucroc score  : 0.9343194961547852 , f1 score     : 0.7628955841064453 \n",
      "Generating predictions and computing metrics for Epoch 4 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.5666930675506592 , training acc : 0.756403386592865 , mcc score : 0.6668528318405151\n",
      "aucroc score  : 0.9312130212783813 , f1 score     : 0.7611462473869324 \n",
      "Generating predictions and computing metrics for Epoch 5 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.5734370946884155 , training acc : 0.7521344423294067 , mcc score : 0.6861110329627991\n",
      "aucroc score  : 0.9381656646728516 , f1 score     : 0.776817262172699 \n",
      "Generating predictions and computing metrics for Epoch 6 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 0.5668790340423584 , training acc : 0.7668089866638184 , mcc score : 0.6563896536827087\n",
      "aucroc score  : 0.930621325969696 , f1 score     : 0.7398738861083984 \n",
      "Generating predictions and computing metrics for Epoch 7 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.5603080987930298 , training acc : 0.7689434289932251 , mcc score : 0.6656412482261658\n",
      "aucroc score  : 0.9347633123397827 , f1 score     : 0.7420811653137207 \n",
      "Generating predictions and computing metrics for Epoch 8 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.5494890809059143 , training acc : 0.77214515209198 , mcc score : 0.6810797452926636\n",
      "aucroc score  : 0.9393491148948669 , f1 score     : 0.7677403092384338 \n",
      "Generating predictions and computing metrics for Epoch 9 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 0.5466548204421997 , training acc : 0.7793489694595337 , mcc score : 0.6748747825622559\n",
      "aucroc score  : 0.9368342757225037 , f1 score     : 0.7622221112251282 \n",
      "Generating predictions and computing metrics for Epoch 10 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 0.530711829662323 , training acc : 0.7793489694595337 , mcc score : 0.6726681590080261\n",
      "aucroc score  : 0.9360946416854858 , f1 score     : 0.752659022808075 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>▆▁▆▅█▅▆█▇▇</td></tr><tr><td>epoch/accuracy</td><td>▁▆▇▆▆▇▇▇██</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▂▂▂▂▂▂▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▄▁▇▆█▅▆█▇▆</td></tr><tr><td>epoch/val_loss</td><td>█▇▃▃▁▄▄▁▁▂</td></tr><tr><td>fmeasure</td><td>▄▁▇▇█▅▆▇▇▆</td></tr><tr><td>mcc</td><td>▄▁▇▆█▅▆█▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>0.93609</td></tr><tr><td>epoch/accuracy</td><td>0.77935</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.00328</td></tr><tr><td>epoch/loss</td><td>0.53071</td></tr><tr><td>epoch/val_accuracy</td><td>0.79167</td></tr><tr><td>epoch/val_loss</td><td>0.51794</td></tr><tr><td>fmeasure</td><td>0.75266</td></tr><tr><td>mcc</td><td>0.67267</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cerulean-sweep-5</strong> at: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/wgrkt0cq' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/wgrkt0cq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230809_001136-wgrkt0cq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hxu1sc6r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_1: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_2: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_3: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0026813045777777256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Projects\\pneumonia-xray-classification\\notebooks\\wandb\\run-20230809_002814-hxu1sc6r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/hxu1sc6r' target=\"_blank\">clear-sweep-6</a></strong> to <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/hxu1sc6r' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/hxu1sc6r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4684 files belonging to 3 classes.\n",
      "Using 3748 files for training.\n",
      "Using 936 files for validation.\n",
      "Found 1172 files belonging to 3 classes.\n",
      "Generating predictions and computing metrics for Epoch 1 \n",
      "30/30 [==============================] - 4s 68ms/step\n",
      "training loss : 1.2837592363357544 , training acc : 0.36739593744277954 , mcc score : 0.20391075313091278\n",
      "aucroc score  : 0.6789940595626831 , f1 score     : 0.3914754390716553 \n",
      "Generating predictions and computing metrics for Epoch 2 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 1.169830560684204 , training acc : 0.42822837829589844 , mcc score : 0.44952473044395447\n",
      "aucroc score  : 0.8159763813018799 , f1 score     : 0.615407407283783 \n",
      "Generating predictions and computing metrics for Epoch 3 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 1.0506260395050049 , training acc : 0.4941301941871643 , mcc score : 0.5345579385757446\n",
      "aucroc score  : 0.853402316570282 , f1 score     : 0.6724088788032532 \n",
      "Generating predictions and computing metrics for Epoch 4 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.9884754419326782 , training acc : 0.534151554107666 , mcc score : 0.5457237958908081\n",
      "aucroc score  : 0.8640532493591309 , f1 score     : 0.6811527609825134 \n",
      "Generating predictions and computing metrics for Epoch 5 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.9451005458831787 , training acc : 0.5610992312431335 , mcc score : 0.5657206773757935\n",
      "aucroc score  : 0.8770710229873657 , f1 score     : 0.6938519477844238 \n",
      "Generating predictions and computing metrics for Epoch 6 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.9357118010520935 , training acc : 0.5781750082969666 , mcc score : 0.5836293697357178\n",
      "aucroc score  : 0.8881656527519226 , f1 score     : 0.7060134410858154 \n",
      "Generating predictions and computing metrics for Epoch 7 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.8804057836532593 , training acc : 0.6085912585258484 , mcc score : 0.5878167748451233\n",
      "aucroc score  : 0.8930473327636719 , f1 score     : 0.7093455195426941 \n",
      "Generating predictions and computing metrics for Epoch 8 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.8614368438720703 , training acc : 0.6155282855033875 , mcc score : 0.5974946022033691\n",
      "aucroc score  : 0.8940829038619995 , f1 score     : 0.7171656489372253 \n",
      "Generating predictions and computing metrics for Epoch 9 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 0.8505856394767761 , training acc : 0.6334044933319092 , mcc score : 0.60422283411026\n",
      "aucroc score  : 0.8994082808494568 , f1 score     : 0.7226438522338867 \n",
      "Generating predictions and computing metrics for Epoch 10 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.8343570828437805 , training acc : 0.6339380741119385 , mcc score : 0.6090036630630493\n",
      "aucroc score  : 0.9044378995895386 , f1 score     : 0.7255281805992126 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>▁▅▆▇▇▇████</td></tr><tr><td>epoch/accuracy</td><td>▁▃▄▅▆▇▇███</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▄▃▃▃▂▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▅▇▇▇█████</td></tr><tr><td>epoch/val_loss</td><td>█▅▄▃▃▂▂▁▁▁</td></tr><tr><td>fmeasure</td><td>▁▆▇▇▇█████</td></tr><tr><td>mcc</td><td>▁▅▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>0.90444</td></tr><tr><td>epoch/accuracy</td><td>0.63394</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.00268</td></tr><tr><td>epoch/loss</td><td>0.83436</td></tr><tr><td>epoch/val_accuracy</td><td>0.75</td></tr><tr><td>epoch/val_loss</td><td>0.67346</td></tr><tr><td>fmeasure</td><td>0.72553</td></tr><tr><td>mcc</td><td>0.609</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clear-sweep-6</strong> at: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/hxu1sc6r' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/hxu1sc6r</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230809_002814-hxu1sc6r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2byke113 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_1: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_2: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_3: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0035670547661196513\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Projects\\pneumonia-xray-classification\\notebooks\\wandb\\run-20230809_004456-2byke113</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/2byke113' target=\"_blank\">fancy-sweep-7</a></strong> to <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/2byke113' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/2byke113</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4684 files belonging to 3 classes.\n",
      "Using 3748 files for training.\n",
      "Using 936 files for validation.\n",
      "Found 1172 files belonging to 3 classes.\n",
      "Generating predictions and computing metrics for Epoch 1 \n",
      "30/30 [==============================] - 4s 69ms/step\n",
      "training loss : 1.0339303016662598 , training acc : 0.4751867651939392 , mcc score : 0.5298065543174744\n",
      "aucroc score  : 0.8232249021530151 , f1 score     : 0.6620423793792725 \n",
      "Generating predictions and computing metrics for Epoch 2 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.8468906879425049 , training acc : 0.6315368413925171 , mcc score : 0.6114137768745422\n",
      "aucroc score  : 0.8878698348999023 , f1 score     : 0.7229201197624207 \n",
      "Generating predictions and computing metrics for Epoch 3 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.7706796526908875 , training acc : 0.6659551858901978 , mcc score : 0.6407026648521423\n",
      "aucroc score  : 0.9084320068359375 , f1 score     : 0.7430796027183533 \n",
      "Generating predictions and computing metrics for Epoch 4 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.7327618598937988 , training acc : 0.6883671283721924 , mcc score : 0.6466076374053955\n",
      "aucroc score  : 0.9146450161933899 , f1 score     : 0.7438343167304993 \n",
      "Generating predictions and computing metrics for Epoch 5 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.7082410454750061 , training acc : 0.7014407515525818 , mcc score : 0.6421022415161133\n",
      "aucroc score  : 0.9155325293540955 , f1 score     : 0.7454233169555664 \n",
      "Generating predictions and computing metrics for Epoch 6 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 0.686355471611023 , training acc : 0.7070437669754028 , mcc score : 0.6482726335525513\n",
      "aucroc score  : 0.9199703931808472 , f1 score     : 0.7458043694496155 \n",
      "Generating predictions and computing metrics for Epoch 7 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 0.6873743534088135 , training acc : 0.715848445892334 , mcc score : 0.6463982462882996\n",
      "aucroc score  : 0.920710027217865 , f1 score     : 0.7455892562866211 \n",
      "Generating predictions and computing metrics for Epoch 8 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 0.6692055463790894 , training acc : 0.7134471535682678 , mcc score : 0.6532567143440247\n",
      "aucroc score  : 0.9221892952919006 , f1 score     : 0.7499522566795349 \n",
      "Generating predictions and computing metrics for Epoch 9 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.6582627296447754 , training acc : 0.7262539863586426 , mcc score : 0.6606829166412354\n",
      "aucroc score  : 0.9245562553405762 , f1 score     : 0.7598124146461487 \n",
      "Generating predictions and computing metrics for Epoch 10 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 0.6558077931404114 , training acc : 0.7307897806167603 , mcc score : 0.6677420735359192\n",
      "aucroc score  : 0.9284023642539978 , f1 score     : 0.7646118998527527 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>▁▅▇▇▇▇▇███</td></tr><tr><td>epoch/accuracy</td><td>▁▅▆▇▇▇████</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▅▃▂▂▂▂▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▅▇▇▇▇▇▇██</td></tr><tr><td>epoch/val_loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr><tr><td>fmeasure</td><td>▁▅▇▇▇▇▇▇██</td></tr><tr><td>mcc</td><td>▁▅▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>0.9284</td></tr><tr><td>epoch/accuracy</td><td>0.73079</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.00357</td></tr><tr><td>epoch/loss</td><td>0.65581</td></tr><tr><td>epoch/val_accuracy</td><td>0.7906</td></tr><tr><td>epoch/val_loss</td><td>0.54344</td></tr><tr><td>fmeasure</td><td>0.76461</td></tr><tr><td>mcc</td><td>0.66774</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fancy-sweep-7</strong> at: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/2byke113' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/2byke113</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230809_004456-2byke113\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nnchghs6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_1: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_2: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_3: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.002516912228228051\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Projects\\pneumonia-xray-classification\\notebooks\\wandb\\run-20230809_005523-nnchghs6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/nnchghs6' target=\"_blank\">youthful-sweep-8</a></strong> to <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/nnchghs6' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/nnchghs6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4684 files belonging to 3 classes.\n",
      "Using 3748 files for training.\n",
      "Using 936 files for validation.\n",
      "Found 1172 files belonging to 3 classes.\n",
      "Generating predictions and computing metrics for Epoch 1 \n",
      "30/30 [==============================] - 4s 68ms/step\n",
      "training loss : 0.743969738483429 , training acc : 0.6934365034103394 , mcc score : 0.6503521203994751\n",
      "aucroc score  : 0.9196745753288269 , f1 score     : 0.7490225434303284 \n",
      "Generating predictions and computing metrics for Epoch 2 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.6092159748077393 , training acc : 0.7451974153518677 , mcc score : 0.6426697969436646\n",
      "aucroc score  : 0.9353550672531128 , f1 score     : 0.7198636531829834 \n",
      "Generating predictions and computing metrics for Epoch 3 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.5714158415794373 , training acc : 0.7705442905426025 , mcc score : 0.6709117293357849\n",
      "aucroc score  : 0.9294378161430359 , f1 score     : 0.7605517506599426 \n",
      "Generating predictions and computing metrics for Epoch 4 \n",
      "30/30 [==============================] - 2s 64ms/step\n",
      "training loss : 0.5626063346862793 , training acc : 0.7636072635650635 , mcc score : 0.6819138526916504\n",
      "aucroc score  : 0.9321006536483765 , f1 score     : 0.7671694159507751 \n",
      "Generating predictions and computing metrics for Epoch 5 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.5598493218421936 , training acc : 0.773479163646698 , mcc score : 0.6867579817771912\n",
      "aucroc score  : 0.9313609600067139 , f1 score     : 0.780734121799469 \n",
      "Generating predictions and computing metrics for Epoch 6 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.5431255102157593 , training acc : 0.7774813175201416 , mcc score : 0.693335771560669\n",
      "aucroc score  : 0.9405325055122375 , f1 score     : 0.779795229434967 \n",
      "Generating predictions and computing metrics for Epoch 7 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.530805230140686 , training acc : 0.777214527130127 , mcc score : 0.7009411454200745\n",
      "aucroc score  : 0.9439349174499512 , f1 score     : 0.7813549041748047 \n",
      "Generating predictions and computing metrics for Epoch 8 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.5635192394256592 , training acc : 0.7732123732566833 , mcc score : 0.6873526573181152\n",
      "aucroc score  : 0.9360946416854858 , f1 score     : 0.7769286036491394 \n",
      "Generating predictions and computing metrics for Epoch 9 \n",
      "30/30 [==============================] - 2s 66ms/step\n",
      "training loss : 0.5456027984619141 , training acc : 0.7649412751197815 , mcc score : 0.6985146999359131\n",
      "aucroc score  : 0.9418638944625854 , f1 score     : 0.789666473865509 \n",
      "Generating predictions and computing metrics for Epoch 10 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.5339304208755493 , training acc : 0.7796158194541931 , mcc score : 0.6990383267402649\n",
      "aucroc score  : 0.9368342757225037 , f1 score     : 0.7839877009391785 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>▁▆▄▅▄▇█▆▇▆</td></tr><tr><td>epoch/accuracy</td><td>▁▅▇▇███▇▇█</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▂▂▂▁▁▂▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▁▄▆▆▇█▆██</td></tr><tr><td>epoch/val_loss</td><td>█▅▄▂▁▂▁▂▂▂</td></tr><tr><td>fmeasure</td><td>▄▁▅▆▇▇▇▇█▇</td></tr><tr><td>mcc</td><td>▂▁▄▆▆▇█▆██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>0.93683</td></tr><tr><td>epoch/accuracy</td><td>0.77962</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.00252</td></tr><tr><td>epoch/loss</td><td>0.53393</td></tr><tr><td>epoch/val_accuracy</td><td>0.80983</td></tr><tr><td>epoch/val_loss</td><td>0.48586</td></tr><tr><td>fmeasure</td><td>0.78399</td></tr><tr><td>mcc</td><td>0.69904</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">youthful-sweep-8</strong> at: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/nnchghs6' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/nnchghs6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230809_005523-nnchghs6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ct6xumlq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_1: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_2: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_3: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0023139288663241784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Projects\\pneumonia-xray-classification\\notebooks\\wandb\\run-20230809_010548-ct6xumlq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/ct6xumlq' target=\"_blank\">splendid-sweep-9</a></strong> to <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/ct6xumlq' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/ct6xumlq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4684 files belonging to 3 classes.\n",
      "Using 3748 files for training.\n",
      "Using 936 files for validation.\n",
      "Found 1172 files belonging to 3 classes.\n",
      "Generating predictions and computing metrics for Epoch 1 \n",
      "30/30 [==============================] - 4s 69ms/step\n",
      "training loss : 0.9895410537719727 , training acc : 0.5635005235671997 , mcc score : 0.6366035342216492\n",
      "aucroc score  : 0.9152366518974304 , f1 score     : 0.7504437565803528 \n",
      "Generating predictions and computing metrics for Epoch 2 \n",
      "30/30 [==============================] - 2s 64ms/step\n",
      "training loss : 0.7798392176628113 , training acc : 0.6672891974449158 , mcc score : 0.6345846652984619\n",
      "aucroc score  : 0.9084319472312927 , f1 score     : 0.7447826862335205 \n",
      "Generating predictions and computing metrics for Epoch 3 \n",
      "30/30 [==============================] - 2s 64ms/step\n",
      "training loss : 0.7191582322120667 , training acc : 0.6851654052734375 , mcc score : 0.6459968686103821\n",
      "aucroc score  : 0.9276626706123352 , f1 score     : 0.7424702048301697 \n",
      "Generating predictions and computing metrics for Epoch 4 \n",
      "30/30 [==============================] - 2s 64ms/step\n",
      "training loss : 0.6876885294914246 , training acc : 0.7083777785301208 , mcc score : 0.6561996340751648\n",
      "aucroc score  : 0.9220414161682129 , f1 score     : 0.7485113143920898 \n",
      "Generating predictions and computing metrics for Epoch 5 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.6728752255439758 , training acc : 0.7073105573654175 , mcc score : 0.6583948135375977\n",
      "aucroc score  : 0.9282544255256653 , f1 score     : 0.7563405632972717 \n",
      "Generating predictions and computing metrics for Epoch 6 \n",
      "30/30 [==============================] - 2s 64ms/step\n",
      "training loss : 0.6566717028617859 , training acc : 0.7163820862770081 , mcc score : 0.6655413508415222\n",
      "aucroc score  : 0.9313609004020691 , f1 score     : 0.760054349899292 \n",
      "Generating predictions and computing metrics for Epoch 7 \n",
      "30/30 [==============================] - 2s 64ms/step\n",
      "training loss : 0.673723042011261 , training acc : 0.7166488766670227 , mcc score : 0.653350830078125\n",
      "aucroc score  : 0.9263314008712769 , f1 score     : 0.7427563071250916 \n",
      "Generating predictions and computing metrics for Epoch 8 \n",
      "30/30 [==============================] - 2s 63ms/step\n",
      "training loss : 0.6439846158027649 , training acc : 0.714514434337616 , mcc score : 0.6645116806030273\n",
      "aucroc score  : 0.9315088987350464 , f1 score     : 0.7578297257423401 \n",
      "Generating predictions and computing metrics for Epoch 9 \n",
      "30/30 [==============================] - 2s 63ms/step\n",
      "training loss : 0.6484293341636658 , training acc : 0.722785472869873 , mcc score : 0.6656842231750488\n",
      "aucroc score  : 0.9298816323280334 , f1 score     : 0.7576786875724792 \n",
      "Generating predictions and computing metrics for Epoch 10 \n",
      "30/30 [==============================] - 2s 65ms/step\n",
      "training loss : 0.6440679430961609 , training acc : 0.7262539863586426 , mcc score : 0.6770380139350891\n",
      "aucroc score  : 0.9315088987350464 , f1 score     : 0.7653787732124329 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>▃▁▇▅▇█▆███</td></tr><tr><td>epoch/accuracy</td><td>▁▅▆▇▇██▇██</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▃▂▂▁▂▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▂▃▅▅▆▄▆▆█</td></tr><tr><td>epoch/val_loss</td><td>█▆▅▃▂▂▃▂▂▁</td></tr><tr><td>fmeasure</td><td>▃▂▁▃▅▆▁▆▆█</td></tr><tr><td>mcc</td><td>▁▁▃▅▅▆▄▆▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>0.93151</td></tr><tr><td>epoch/accuracy</td><td>0.72625</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.00231</td></tr><tr><td>epoch/loss</td><td>0.64407</td></tr><tr><td>epoch/val_accuracy</td><td>0.79701</td></tr><tr><td>epoch/val_loss</td><td>0.51107</td></tr><tr><td>fmeasure</td><td>0.76538</td></tr><tr><td>mcc</td><td>0.67704</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">splendid-sweep-9</strong> at: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/ct6xumlq' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/ct6xumlq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230809_010548-ct6xumlq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pb39ak29 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_1: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_2: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_3: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004039459423685297\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Projects\\pneumonia-xray-classification\\notebooks\\wandb\\run-20230809_011745-pb39ak29</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/pb39ak29' target=\"_blank\">woven-sweep-10</a></strong> to <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/sweeps/kjecbfle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/pb39ak29' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/pb39ak29</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4684 files belonging to 3 classes.\n",
      "Using 3748 files for training.\n",
      "Using 936 files for validation.\n",
      "Found 1172 files belonging to 3 classes.\n",
      "Generating predictions and computing metrics for Epoch 1 \n",
      "30/30 [==============================] - 4s 70ms/step\n",
      "training loss : 0.7202815413475037 , training acc : 0.7022411823272705 , mcc score : 0.6619464755058289\n",
      "aucroc score  : 0.9303253889083862 , f1 score     : 0.7442891001701355 \n",
      "Generating predictions and computing metrics for Epoch 2 \n",
      "30/30 [==============================] - 2s 67ms/step\n",
      "training loss : 0.5744310617446899 , training acc : 0.7676094174385071 , mcc score : 0.6741309762001038\n",
      "aucroc score  : 0.9359467029571533 , f1 score     : 0.7437850832939148 \n",
      "Generating predictions and computing metrics for Epoch 3 \n",
      "30/30 [==============================] - 2s 67ms/step\n",
      "training loss : 0.5164772272109985 , training acc : 0.7897545099258423 , mcc score : 0.68256676197052\n",
      "aucroc score  : 0.9331360459327698 , f1 score     : 0.7729905247688293 \n",
      "Generating predictions and computing metrics for Epoch 4 \n",
      "30/30 [==============================] - 2s 67ms/step\n",
      "training loss : 0.5006155371665955 , training acc : 0.7966915965080261 , mcc score : 0.6864165663719177\n",
      "aucroc score  : 0.9328402876853943 , f1 score     : 0.7762762904167175 \n",
      "Generating predictions and computing metrics for Epoch 5 \n",
      "30/30 [==============================] - 2s 68ms/step\n",
      "training loss : 0.4951923191547394 , training acc : 0.7945570945739746 , mcc score : 0.6708487868309021\n",
      "aucroc score  : 0.9349112510681152 , f1 score     : 0.7521821856498718 \n",
      "Generating predictions and computing metrics for Epoch 6 \n",
      "30/30 [==============================] - 2s 67ms/step\n",
      "training loss : 0.4740303158760071 , training acc : 0.8049626350402832 , mcc score : 0.7034583687782288\n",
      "aucroc score  : 0.9400887489318848 , f1 score     : 0.7859036326408386 \n",
      "Generating predictions and computing metrics for Epoch 7 \n",
      "30/30 [==============================] - 2s 68ms/step\n",
      "training loss : 0.4580918550491333 , training acc : 0.8140341639518738 , mcc score : 0.69802325963974\n",
      "aucroc score  : 0.9392011761665344 , f1 score     : 0.7793533802032471 \n",
      "Generating predictions and computing metrics for Epoch 8 \n",
      "30/30 [==============================] - 2s 67ms/step\n",
      "training loss : 0.47150617837905884 , training acc : 0.8081643581390381 , mcc score : 0.6862397789955139\n",
      "aucroc score  : 0.9399408102035522 , f1 score     : 0.769146740436554 \n",
      "Generating predictions and computing metrics for Epoch 9 \n",
      "30/30 [==============================] - 2s 67ms/step\n",
      "training loss : 0.463900625705719 , training acc : 0.7990928292274475 , mcc score : 0.7036632299423218\n",
      "aucroc score  : 0.9430473446846008 , f1 score     : 0.7915763258934021 \n",
      "Generating predictions and computing metrics for Epoch 10 \n",
      "30/30 [==============================] - 2s 70ms/step\n",
      "training loss : 0.4554869830608368 , training acc : 0.8167022466659546 , mcc score : 0.6989369988441467\n",
      "aucroc score  : 0.9402366876602173 , f1 score     : 0.7822839617729187 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>▁▄▃▂▄▆▆▆█▆</td></tr><tr><td>epoch/accuracy</td><td>▁▅▆▇▇▇█▇▇█</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▃▂▂▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▃▄▅▂█▇▅█▇</td></tr><tr><td>epoch/val_loss</td><td>█▄▃▂▅▂▂▂▁▂</td></tr><tr><td>fmeasure</td><td>▁▁▅▆▂▇▆▅█▇</td></tr><tr><td>mcc</td><td>▁▃▄▅▂█▇▅█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auc_roc</td><td>0.94024</td></tr><tr><td>epoch/accuracy</td><td>0.8167</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.0004</td></tr><tr><td>epoch/loss</td><td>0.45549</td></tr><tr><td>epoch/val_accuracy</td><td>0.80876</td></tr><tr><td>epoch/val_loss</td><td>0.47242</td></tr><tr><td>fmeasure</td><td>0.78228</td></tr><tr><td>mcc</td><td>0.69894</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">woven-sweep-10</strong> at: <a href='https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/pb39ak29' target=\"_blank\">https://wandb.ai/marcus-lim/PCXR-evaluating-densenet-model-variations/runs/pb39ak29</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230809_011745-pb39ak29\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=sweep_train, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close WandB run:\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
